{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from model import LabelSmoothing,NoamOpt,SimpleLossCompute,make_model,run_epoch\n",
    "from util import Batch\n",
    "from util import greedy_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Transformer Task')\n",
    "parser.add_argument('--dataset', type=str, default='phi',choices=['RMSD','phi','psi'])\n",
    "parser.add_argument('--unidirection', type=bool, default=False)\n",
    "parser.add_argument('--gpu_id', type=str, default='cuda:3')\n",
    "#args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data are provided with 1.0ps as saving interval\n",
    "if args.dataset=='RMSD':\n",
    "    train,valid=np.loadtxt('data/alanine/train',dtype=int),np.loadtxt('data/alanine/valid',dtype=int)\n",
    "    train=train.reshape(-1,100)\n",
    "    valid=valid.reshape(-1,100)\n",
    "elif args.dataset=='phi':\n",
    "    train,valid=np.loadtxt('data/phi-psi/train_phi_1.0ps',dtype=int),np.loadtxt('data/phi-psi/valid_phi_1.0ps',dtype=int)\n",
    "elif args.dataset=='psi':\n",
    "    train,valid=np.loadtxt('data/phi-psi/train_psi_1.0ps',dtype=int),np.loadtxt('data/phi-psi/valid_psi_1.0ps',dtype=int)\n",
    "     \n",
    "lag=1\n",
    "log_dir=\"logs/fit/{}_{}ps/\".format(args.dataset,lag)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "save_dir = 'result/{}_{}ps/'.format(args.dataset,lag)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "ckpt_dir='ckpt/training_checkpoints_{}_{}ps/'.format(args.dataset,lag)\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "device= torch.device(args.gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(fulldata, batch,pad):\n",
    "    nbatches=int(fulldata.shape[0]//batch)\n",
    "    \"Generate random data for a src copy task.\"\n",
    "    choice=[i for i in range(nbatches)]  \n",
    "    random.shuffle(choice)\n",
    "    for i in choice:\n",
    "        data=fulldata[i*batch:(i+1)*batch]      \n",
    "        src = Variable(torch.from_numpy(data), requires_grad=False)\n",
    "        yield Batch(src.to(device), src.to(device), pad,uni=args.unidirection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = len(np.unique(train))\n",
    "pad=V+1\n",
    "criterion = LabelSmoothing(size=V, padding_idx=pad, smoothing=0.0)\n",
    "model = make_model(V, V, N=2)\n",
    "model.to(device)\n",
    "model_opt = NoamOpt(model.src_embed[0].d_model, 1, 400,\n",
    "        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the simple copy task.\n",
    "V = len(np.unique(train))\n",
    "pad=V+1\n",
    "criterion = LabelSmoothing(size=V, padding_idx=pad, smoothing=0.0)\n",
    "model = make_model(V, V, N=2)\n",
    "model.to(device)\n",
    "model_opt = NoamOpt(model.src_embed[0].d_model, 1, 400,\n",
    "        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "for epoch in range(201):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    loss_train=run_epoch(data_generator(train, 32, pad), model, \n",
    "              SimpleLossCompute(model.generator, criterion, model_opt,device))\n",
    "    elapsed = time.time() - start\n",
    "    print(\"Epoch  %d  Time: %f\" %\n",
    "                    (epoch, elapsed))\n",
    "    model.eval()\n",
    "    loss_valid=run_epoch(data_gen(valid, 32, pad), model, \n",
    "                    SimpleLossCompute(model.generator, criterion, None,device))\n",
    "    if epoch<5 or epoch%5==0:\n",
    "        torch.save(model.state_dict(), ckpt_dir+'epoch{}.pt'.format(epoch))\n",
    "    writer.add_scalar('Loss/train', loss_train, epoch)\n",
    "    writer.add_scalar('Loss/test', loss_valid, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "num_generate=10\n",
    "ckpt_dir='ckpt/training_checkpoints_Ldata_phi_1ps/'\n",
    "for epoch in [2,5,90,100]:\n",
    "    model.load_state_dict(torch.load(ckpt_dir+'epoch{}.pt'.format(epoch)))\n",
    "    for i in range(100):\n",
    "        text4activation=train.reshape(-1)[i*80000:(i+1)*80000]   #for phi!\n",
    "        start0 = time.time()\n",
    "        src = Variable(torch.from_numpy(text4activation[-5000:]).unsqueeze(0)).to(device)\n",
    "        src_mask = (src != pad).unsqueeze(-2)\n",
    "        start_symbol=src[-1][-1]\n",
    "\n",
    "        prediction=greedy_decode(model, src, src_mask, max_len=num_generate, start_symbol=start_symbol,pad=pad)\n",
    "        print ('Time taken for total {} sec\\n'.format(time.time() - start0))\n",
    "        save=save_dir+'epoch{}/'.format(epoch)\n",
    "        os.makedirs(save, exist_ok=True)\n",
    "        np.savetxt(save+'prediction_'+str(i),prediction.cpu(),fmt='%i')\n",
    "    print('epoch{} done'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
